# Quick Reference: Personal AI Companion Architecture

## ğŸ¯ One-Page Overview

### Core Architecture Pattern

```
User â†’ Voice/Text Input
  â†“
ElevenLabs (WebRTC) â†’ Speech-to-Text
  â†“
Main Companion Agent (GPT-4o)
  â†“
Memory Recall (Pinecone Vector Search)
  â†“
Specialist Routing (LangGraph)
  â”œâ†’ Health Specialist (Claude Opus)
  â”œâ†’ Nutrition Expert (GPT-4o-mini)
  â””â†’ Mental Wellness (Claude Haiku)
  â†“
Response Generation
  â†“
Nudge Engine (Behavioral Economics)
  â†“
Text-to-Speech (ElevenLabs)
  â†“
User â† Voice/Text Output
```

---

## ğŸ’¾ Memory System (5 Pillars)

```typescript
// 1. EXTRACT facts from conversation
const facts = await extractFacts(userMessage, aiResponse);

// 2. EMBED and store in vector DB
await pinecone.upsert(facts, userId);

// 3. COMPRESS older context
const summary = await compressContext(messages.slice(0, -3));

// 4. RECALL relevant memories
const memories = await pinecone.search(query, userId);

// 5. LEARN from feedback
await updatePreferences(userFeedback);
```

**Key Metrics:**
- 26% accuracy boost vs OpenAI memory
- 90% token reduction via compression
- Sub-50ms vector search latency

---

## ğŸ¤– Multi-Agent Pattern

```typescript
// LangGraph state machine
const workflow = new StateGraph(CompanionState)
  .addNode("main", mainCompanionNode)
  .addNode("health", healthSpecialistNode)
  .addNode("nutrition", nutritionExpertNode)
  .addConditionalEdges("main", routeToSpecialist)
  .compile();

// Routing logic
function routeToSpecialist(state) {
  if (/symptom|medication/i.test(lastMessage)) return 'health';
  if (/diet|nutrition/i.test(lastMessage)) return 'nutrition';
  return 'continue';
}
```

**When to Use:**
- ğŸ¥ Health questions â†’ Claude Opus (best medical reasoning)
- ğŸ¥— Nutrition â†’ GPT-4o-mini (cost-effective)
- ğŸ§  Mental health â†’ Claude Haiku (fast, empathetic)
- ğŸ’¬ General chat â†’ GPT-4o (balanced)

---

## ğŸ™ï¸ Voice Pipeline

```typescript
// Initialize ElevenLabs WebRTC
const conversation = await Conversation.create({
  agentId: process.env.ELEVENLABS_AGENT_ID,
  transport: { type: 'webrtc' },
  clientSettings: {
    turnTakingMode: 'natural',
    voice: { voiceId: 'custom_clone' }
  }
});

// Handle events
conversation.on('partialTranscript', updateLiveText);
conversation.on('agentTurnComplete', saveToMemory);
conversation.on('userInterrupted', stopSpeaking);
```

**Performance:**
- <200ms latency (p95)
- Natural turn-taking (understands "um", "ah")
- WebRTC-native (no plugins)

---

## ğŸ¯ Behavioral Nudge Engine

```typescript
// Select personalized nudge
const nudge = await nudgeEngine.select(userId, context);

// Nudge types by effectiveness
const nudgeHierarchy = {
  automated: 0.93,      // Highest (e.g., default options)
  lossAversion: 0.75,   // "Don't break your streak!"
  socialProof: 0.68,    // "1000 people did this today"
  gamification: 0.62,   // "Unlock achievement"
  commitment: 0.58      // "You committed to..."
};

// A/B test variant
const variant = hashUserId(userId) % variants.length;

// Track & analyze
await analytics.track('nudge_shown', { userId, variant });
```

**Ethical Boundaries:**
- âœ… Explicit opt-in required
- âœ… Transparent explanations
- âœ… One-click disable
- âŒ No dark patterns

---

## ğŸ” Privacy Architecture

```typescript
// Data classification
const dataPolicy = {
  edge: {
    storage: 'IndexedDB (encrypted)',
    data: ['health_conditions', 'medications', 'biometrics'],
    processing: 'TensorFlow.js (local)'
  },

  cloud: {
    storage: 'Supabase (AES-256)',
    data: ['goals', 'preferences', 'anonymized_stats'],
    sharing: 'explicit_consent_only'
  },

  federated: {
    learning: 'differential_privacy (Îµ=0.1)',
    aggregation: 'secure_aggregation',
    minParticipants: 100
  }
};
```

**Compliance:**
- âœ… HIPAA Technical Safeguards
- âœ… GDPR Right to Erasure
- âœ… Differential Privacy (Îµ=0.1)

---

## ğŸ’° Cost Optimization

```typescript
// 1. Context Compression (80% reduction)
const compressed = await summarize(messages.slice(0, -3));
// Savings: $2.50 â†’ $0.50 per user

// 2. Smart Model Routing
const model = selectModel(query);
// Simple â†’ Groq ($0.27/1M) = 90% savings
// Complex â†’ GPT-4o ($2.50/1M)

// 3. Response Caching (50% hit rate)
const cached = await redis.get(queryHash);
if (cached) return cached; // Free!

// 4. Selective Voice (30% usage)
if (shouldUseVoice(response)) {
  await elevenLabs.speak(response);
}
// Savings: $2.40 â†’ $0.72 per user
```

**Cost Breakdown:**
```
Without optimization: $5.17 per user
With optimization:    $0.66 per user (87% savings)
```

---

## ğŸš€ Tech Stack Cheat Sheet

### Database Layer
```yaml
Structured:  Supabase (PostgreSQL)
Vector:      Pinecone Serverless
Cache:       Upstash Redis
Graph:       Neo4j (optional Phase 2)
```

### AI Layer
```yaml
Memory:      Mem0 pattern
Agents:      LangGraph + ACP
LLMs:        GPT-4o + Groq + Claude
Voice:       ElevenLabs Conversational AI
Embeddings:  text-embedding-3-large
```

### Infrastructure
```yaml
Hosting:     Vercel (start) â†’ Cloudflare (scale)
CDN:         Vercel Edge Network
Edge:        Cloudflare Workers
Stateful:    Fly.io (self-hosted services)
```

### Monitoring
```yaml
Errors:      Sentry
Analytics:   PostHog
Logs:        Better Stack
APM:         Vercel Analytics
```

---

## ğŸ“Š Performance Targets

| Metric | Target | Current Benchmark |
|--------|--------|-------------------|
| Voice Latency | <200ms | âœ… 150ms (ElevenLabs) |
| API Response | <500ms | âœ… 300ms (optimized) |
| Memory Recall | <50ms | âœ… 30ms (Pinecone) |
| Context Window | 128K tokens | âœ… GPT-4o supports |
| Uptime | 99.9% | âœ… Vercel SLA |
| Error Rate | <0.1% | Track in Sentry |

---

## ğŸ—ï¸ Implementation Phases

### Phase 1: Foundation (Weeks 1-3)
```bash
âœ… Set up Pinecone Serverless
âœ… Implement memory extraction
âœ… Build LangGraph agent system
âœ… Deploy to Vercel
```

### Phase 2: Voice (Weeks 4-6)
```bash
âœ… Integrate ElevenLabs WebRTC
âœ… Implement turn-taking
âœ… Build interruption handling
âœ… Voice preference learning
```

### Phase 3: Engagement (Weeks 7-9)
```bash
âœ… Build nudge engine
âœ… A/B testing framework
âœ… ML personalization
âœ… Analytics dashboard
```

### Phase 4: Scale (Weeks 10-12)
```bash
âœ… Federated learning
âœ… Edge encryption
âœ… Auto-scaling
âœ… Production launch
```

---

## ğŸ”§ Quick Commands

### Development
```bash
# Start all services
npm run dev

# Run memory pipeline
npm run memory:test

# Test voice integration
npm run voice:test

# Run agent orchestration
npm run agents:test

# Full test suite
npm run test:all
```

### Deployment
```bash
# Deploy to Vercel
vercel --prod

# Update environment variables
vercel env add PINECONE_API_KEY

# View logs
vercel logs

# Roll back
vercel rollback
```

### Monitoring
```bash
# View Sentry errors
open https://sentry.io/organizations/bearable

# Check PostHog analytics
open https://app.posthog.com

# View logs in Better Stack
open https://logs.betterstack.com
```

---

## ğŸ› Common Issues & Solutions

### High LLM Costs
```typescript
// Problem: $5+ per user
// Solution: Context compression + model routing
await compressContext(messages); // 80% reduction
const model = selectModel(query); // Use Groq for simple
```

### Voice Latency
```typescript
// Problem: >500ms latency
// Solution: WebRTC + streaming
const conversation = await Conversation.create({
  transport: { type: 'webrtc' }, // Not websocket!
  streaming: true
});
```

### Memory Recall Issues
```typescript
// Problem: Irrelevant memories
// Solution: Better embeddings + metadata filtering
await pinecone.search(query, {
  topK: 5,
  filter: {
    timestamp: { $gte: Date.now() - 30 * 24 * 60 * 60 * 1000 },
    relevance: { $gte: 0.7 }
  }
});
```

### Agent Routing Errors
```typescript
// Problem: Wrong specialist called
// Solution: Improve routing logic with embeddings
const intent = await classifyIntent(query);
const specialist = intentToSpecialist[intent];
```

---

## ğŸ“ Code Snippets

### Memory System
```typescript
// Store interaction
await memorySystem.addInteraction(userId, {
  user: userMessage,
  assistant: aiResponse,
  timestamp: Date.now()
});

// Recall context
const { memories, summary } = await memorySystem.recall(
  userId,
  currentQuery
);
```

### Multi-Agent
```typescript
// Invoke agent graph
const result = await companionGraph.invoke({
  messages: [{ role: 'user', content: message }],
  userContext,
  memory: recalledMemories
});
```

### Voice
```typescript
// Initialize voice
await voiceService.initialize({
  userId,
  systemPrompt,
  onTranscript: (text) => updateUI(text),
  onResponse: (text) => saveToMemory(text)
});

// Handle audio
await voiceService.sendAudio(audioBuffer);
```

### Nudge
```typescript
// Select & deliver nudge
const nudge = await nudgeEngine.selectNudge(userId, context);
await nudgeEngine.deliver(nudge, 'push');
await analytics.track('nudge_shown', { userId, nudgeId: nudge.id });
```

---

## ğŸ¯ Decision Tree

### Which Vector DB?
```
Need < 100ms latency? â†’ YES â†’ Pinecone
                      â†’ NO  â†’ Cost sensitive?
                              â†’ YES â†’ Chroma (self-hosted)
                              â†’ NO  â†’ Weaviate (hybrid search)
```

### Which Agent Framework?
```
Complex state management? â†’ YES â†’ LangGraph
                          â†’ NO  â†’ Need simple setup?
                                  â†’ YES â†’ CrewAI
                                  â†’ NO  â†’ AutoGen
```

### Which LLM?
```
Medical reasoning?    â†’ Claude Opus ($15/1M)
Simple query?         â†’ Groq Mixtral ($0.27/1M)
Balanced performance? â†’ GPT-4o ($2.50/1M)
Cost critical?        â†’ GPT-4o-mini ($0.15/1M)
```

### Which Voice Provider?
```
Need < 200ms latency?  â†’ YES â†’ ElevenLabs
Cost > $500/month?     â†’ YES â†’ Custom (AssemblyAI + Play.ht)
                       â†’ NO  â†’ ElevenLabs
```

---

## ğŸ“ˆ Success Metrics

### Technical KPIs
- âœ… Voice latency <200ms (p95)
- âœ… API response <500ms (p95)
- âœ… Memory accuracy >90%
- âœ… Uptime >99.9%

### Business KPIs
- ğŸ¯ 20-40% paid conversion
- ğŸ¯ 40%+ retention improvement
- ğŸ¯ 30%+ nudge engagement
- ğŸ¯ $0.66 cost per user

### User Experience
- ğŸ˜Š >4.5/5 satisfaction
- ğŸ—£ï¸ 50%+ use voice weekly
- ğŸ” 3x daily active usage
- â¤ï¸ >70 NPS score

---

## ğŸš¦ Launch Checklist

### Pre-Launch
- [ ] Memory system tested (1000+ interactions)
- [ ] Voice latency <200ms validated
- [ ] Security audit passed (HIPAA)
- [ ] Cost monitoring in place
- [ ] Error tracking configured
- [ ] Analytics dashboard live
- [ ] A/B tests running

### Launch
- [ ] Gradual rollout (10% â†’ 50% â†’ 100%)
- [ ] Monitor error rates hourly
- [ ] Watch cost metrics daily
- [ ] Collect user feedback
- [ ] Iterate on nudge effectiveness

### Post-Launch
- [ ] Optimize based on data
- [ ] Scale infrastructure
- [ ] Add advanced features
- [ ] Expand specialist agents

---

## ğŸ”— Key Links

**Documentation:**
- Architecture Design: `/ARCHITECTURE_DESIGN.md`
- Implementation Guide: `/IMPLEMENTATION_GUIDE.md`
- Cost Analysis: `/COST_ANALYSIS.md`
- Tech Stack Decisions: `/TECH_STACK_DECISIONS.md`
- Executive Summary: `/EXECUTIVE_SUMMARY.md`

**External Resources:**
- [Pinecone Docs](https://docs.pinecone.io)
- [LangGraph Guide](https://langchain-ai.github.io/langgraph/)
- [ElevenLabs API](https://elevenlabs.io/docs)
- [Mem0 Research](https://mem0.ai/research)

**Monitoring:**
- Sentry: `https://sentry.io/organizations/bearable`
- PostHog: `https://app.posthog.com`
- Vercel: `https://vercel.com/bearable`

---

**This quick reference is your go-to guide for building and scaling the Personal AI Companion. Keep it handy!** ğŸš€
